{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "vocab = set()\n",
    "docs = []\n",
    "\n",
    "D = 472 # number of documents\n",
    "# D = 1\n",
    "K = 10 # number of topics\n",
    "\n",
    "# open each file; convert everything to lowercase and strip non-letter symbols; split into words\n",
    "for fileind in range( 1, D+1 ):\n",
    "    foo = open( 'files/output%04d.txt' % fileind ).read()    \n",
    "    tmp = re.sub( '[^a-z ]+', ' ', foo.lower() ).split()\n",
    "    docs.append( tmp )\n",
    " \n",
    "    for w in tmp:\n",
    "        vocab.add( w )\n",
    "\n",
    "# vocab now has unique words\n",
    "# give each word in the vocab a unique id\n",
    "ind = 0\n",
    "vhash = {}\n",
    "vindhash = {}\n",
    "for i in list(vocab):\n",
    "    vhash[i] = ind\n",
    "    vindhash[ind] = i\n",
    "    ind += 1\n",
    "\n",
    "# size of our vocabulary\n",
    "V = ind\n",
    "\n",
    "# reprocess each document and re-represent it as a list of word ids\n",
    "\n",
    "docs_i = []\n",
    "for d in docs:\n",
    "    dinds = []\n",
    "    for w in d:\n",
    "        dinds.append( vhash[w] )\n",
    "    docs_i.append( dinds )\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "civk = np.zeros((D, V, K)) #should be 3-d?\n",
    "\n",
    "def randomly_assign_topics( docs_inds, K ):\n",
    "    qs = np.zeros((D, V))\n",
    "    for i in range(len(docs_inds)):\n",
    "        doc = docs_inds[i]\n",
    "        # topic = np.random.randint(0, K, len(doc)).flatten()\n",
    "        # topics[i] = topic\n",
    "        for j in range(len(doc)):\n",
    "            qs[i, j] = np.random.randint(0, K)\n",
    "            civk[i, j] = np.eye(K)[int(qs[i, j])]\n",
    "            # civk[i, docs_inds[i][j]] = np.eye(K)[topic[j]]\n",
    "    return qs\n",
    "    \n",
    "def compute_data_likelihood( docs_inds, qs, bs, pis ):\n",
    "    return np.dot(bs, pis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, p=0.00\n",
      "qs done\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "(472,)\n",
      "pis done\n"
     ]
    }
   ],
   "source": [
    "qs = randomly_assign_topics( docs_i, K ) # updates civk\n",
    "\n",
    "alphas = np.ones((K,1))[:,0]\n",
    "gammas = np.ones((V,1))[:,0]\n",
    "\n",
    "# topic distributions\n",
    "bs = np.zeros((V,K))\n",
    "for v in range(V):\n",
    "    bs[v] = np.random.dirichlet(np.ones(K))\n",
    "\n",
    "# per-document-topic distributions\n",
    "pis = np.zeros((K,D))  \n",
    "for k in range(K):\n",
    "    pis[k] = np.random.dirichlet(np.ones(D))\n",
    "\n",
    "for iters in range(0,100):\n",
    "    p = 0 # compute_data_likelihood( docs_i, qs, bs, pis)\n",
    "    print(\"Iter %d, p=%.2f\" % (iters,p))\n",
    "\n",
    "    # resample per-word topic assignments bs\n",
    "\n",
    "    # resample per-document topic mixtures pis\n",
    "\n",
    "    # resample topics\n",
    "    #----------------------------------------------------------------------\n",
    "    # Sample from full conditional of qs\n",
    "    for i in range(D):\n",
    "        doc = docs_i[i]\n",
    "        for d in range(len(doc)):\n",
    "            # Calculate params for Z\n",
    "            p_iv = np.exp(np.log(pis[:, i]) + np.log(bs[doc[d]]))\n",
    "            p_iv /= np.sum(p_iv)\n",
    "\n",
    "            # Resample word topic assignment Z\n",
    "            qs[i, doc[d]] = np.random.multinomial(1, p_iv).argmax()\n",
    "            civk[i, doc[d]] = np.eye(K)[int(qs[i, doc[d]])]\n",
    "    print('qs done')\n",
    "\n",
    "    # Sample from full conditional of pis\n",
    "    for i in range(K):\n",
    "        m = np.argmax(np.sum(civk, axis=1), axis=1)\n",
    "        # Resample doc topic dist.\n",
    "        pis[i, :] = np.random.dirichlet(1 + m)\n",
    "    print('pis done')\n",
    "\n",
    "    # Sample from full conditional of bs\n",
    "    # ---------------------------------\n",
    "    for v in range(V):\n",
    "        n = np.zeros(K)\n",
    "\n",
    "        # Gather sufficient statistics\n",
    "        for k in range(K):\n",
    "            for i in range(D):\n",
    "                doc = docs_i[i]\n",
    "                for l in range(len(doc)):\n",
    "                    n[k] += (doc[l] == k) and (qs[i, doc[l]] == v)\n",
    "\n",
    "        # Resample word topic dist.\n",
    "        bs[v, :] = np.random.dirichlet(1 + n)\n",
    "    print('bs done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
